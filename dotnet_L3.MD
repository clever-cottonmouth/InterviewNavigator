# Transaction Failures & Retry Mechanisms

Q1: During a transaction process, if a transaction fails,
how do you figure it out and make sure it gets reprocessed?

Scenario:
In a financial system, a customer initiates a fund transfer.
Due to a network failure or database timeout, the transaction fails.
How do you ensure it retries automatically without duplication?

The best approach is to use a retry mechanism with idempotency. This can be done via:

**- Implementing a retry policy using Polly:**

```
var retryPolicy = Policy
.Handle<Exception>()
.WaitAndRetry(3, retryAttempt = TimeSpan. FromSeconds(retryAttempt));

retryPolicy.Execute(() = ProcessTransaction(transactionId));
```

* Retries up to 3 times before failing.
* Uses exponential backoff to prevent overload.

**- Using a background job queue (Hangfire, Quartz.NET, or MassTransit):**

2) Using a background job queue (Hangfire, Quartz.NET, or MassTransit) :

* Failed transactions can be pushed to a retry queue for delayed processing.
* The background job polls the queue and retries processing.

**- Database-based tracking:**

3) Database-based tracking:

* Store transactions in a table with a "processing" status.
* If a failure occurs, update the status and retry later.
* Ensures idempotency by checking if the transaction has already been processed before re-executing.

# 2. Deadlocks in SQL Transactions

Q2: In a high-volume transaction system, deadlocks occur frequently.
How do you resolve and prevent them?

Scenario:
Multiple services in a banking system update the customer balance simultaneously.
This leads to frequent deadlocks in SQL.

**- Use a consistent ordering of operations:**

1) Use a consistent ordering of operations:

```
BEGIN TRANSACTION
UPDATE AccountBalance SET Balance = Balance - @amount WHERE AccountId = @sender
UPDATE AccountBalance SET Balance = Balance + @amount WHERE AccountId = @receiver
COMMIT
```

* Always debit before credit to prevent deadlocks.

**- Lower the lock scope:**

2) Lower the lock scope:

Instead of SERIALIZABLE, use READ COMMITTED or SNAPSHOT.

**- Retry logic in case of deadlock:**

3) Retry logic in case of deadlock:

var retryPolicy = Policy.Handle `<SqlException>`(ex = ex.Number = 1205)
.Retry(3);
retryPolicy. Execute(() =ExecuteTransaction());



# 3. Handling High-Volume Concurrent Transactions

Q3: Your bank's payment service is experiencing bottlenecks during peak hours. How do you optimize it?

1) Use CQRS (Command Query Responsibility Segregation):

* Write operations (transactions) go to SQL (normalized).
* Read operations (transaction history, balances) use NoSQL (Elasticsearch, Redis, MongoDB).

2) Event-driven processing (Kafka, RabbitMQ, or Azure Service Bus):

* Instead of writing directly to the database, publish events like TransactionCompleted and process them asynchronously.

3) Partitioning:

* Use sharded databases so that different users' transactions are processed on different servers.

# 4. Preventing Double-Spending in Distributed Transactions


Q4: How do you ensure that a transaction is not processed twice in a distributed system?

1) Implement idempotency keys:

* Every request carries a unique transaction ID (Guid).
* Before processing, check if this ID exists in the database.

2) Two-Phase Commit (2PC) for distributed transactions:

* Prepare phase: The system locks the resources and ensures they can be updated.
* Commit phase: Once all services confirm, the transaction is committed.

3) Use Outbox Pattern:

* Store events in an outbox table before processing.
* A background job picks and processes them exactly once.


# 5. Optimizing Database Queries for Real-Time Processing


Q5: The system is slowing down because some queries take too long.
How do you optimize them?


1) Use database indexing:

CREATE INDEX idx_customer_id ON Transactions(CustomerId);

* This speeds up lookups.

2) Use pagination for large queries:

SELECT * FROM Transactions ORDER BY TransactionDate DESC OFFSET 0 ROWS FETCH NEXT 50 ROWS ONLY;

3) Avoid SELECT *** and retrieve only needed columns.
4) Use read replicas to distribute query loads.

# 6. Securing API Requests & Authentication

Q6: How do you secure API requests in a financial system?

1) Use JWT (JSON Web Tokens) with short expiration (e.g., 5 minutes).
2) Implement rate-limiting to prevent abuse.
3) Encrypt sensitive data in transit (TLS 1.2/1.3) and at rest (AES-256).
4) HMAC Signature Verification for ensuring requests aren't tampered with.

# 7. Handling Long-Running Processes in .NET

Q7: A loan approval process takes 3-5 minutes. How do you handle
this without blocking the system?

* Use asynchronous processing with background jobs (e.g., Hangfire, Azure Functions).
* Expose Webhooks so that once processing is done, the client gets notified.
* Use SignalR for real-time updates instead of polling.


# 8. Handling Race Conditions in Multi-Threaded Environments

Q8: Two customers withdraw from the same account at the same time.
How do you prevent over-withdrawal?


1) Use database transactions with row-level locks:

BEGIN TRANSACTION
UPDATE AccountBalance SET Balance = Balance - @amount WHERE AccountId = @id AND Balance > @amount
COMMIT

* Ensures that if another process updates the balance first, the second one fails gracefully.

2) Use optimistic concurrency with versioning:

* Store a Version column and update only if the version matches.


# 9. Logging & Monitoring in Production


Q9: How do you debug a production issue in a high-traffic financial app?

1) Use structured logging (Serilog, Seq, ELK Stack).
2) Capture correlation IDs for tracing distributed transactions.
3) Monitor metrics using Prometheus + Grafana.


# 10. Handling API Failures in a Microservices Architecture


Q10: A microservice API fails intermittently. How do you prevent
it from affecting the entire system?


1) Use Circuit Breaker (Polly):

var circuitBreaker = Policy
.Handle`<HttpRequestException>`()
.CircuitBreaker(3, TimeSpan.FromSeconds(30));

2) Use a fallback mechanism (e.g., return cached data if the API is down).


# 11. Handling Concurrency in a Banking System

Q11: Two users try to transfer money at the same time. How do you prevent
race conditions and ensure accuracy?

1) Optimistic Concurrency Control (Occ)

* Store a Version column and update only if the version matches.
* Example in SQL:

UPDATE Accounts
SET Balance = Balance - @amount, Version = Version + 1
WHERE AccountId = @id AND Version = @currentVersion

2) Pessimistic Concurrency Control

* Use row-level locking (SELECT ... FOR UPDATE).

3) Eventual Consistency using Distributed Locks

* Use Redis RedLock for distributed locking in microservices.

# 12. Preventing API Rate Abuse

Q12: How do you prevent malicious users from making excessive API calls?

1) Rate limiting with Token Bucket or Leaky Bucket algorithms.
2) Implement API Gateway-based throttling (Kong, Ocelot, Azure API Management)
3) Use IP Whitelisting & Authentication-Based Limits.


# 13. Ensuring Data Consistency Across Microservices

Q13: How do you ensure consistency when multiple microservices update a shared record?

1) Use a Saga Pattern (Orchestration or Choreography).
2) Implement an Outbox Pattern to ensure transactions and events are processed together.
3) Use Eventual Consistency with Kafka for event-driven updates.


# 14. Secure Storage of Sensitive User Data

Q14: How do you store sensitive customer data like card numbers securely?

1) Encrypt data at rest using AES-256
2) Use Hashing with Salt (bcrypt, Argon2) for passwords.
3) Mask card details (e.g., **** **** **** 1234).


# 15. Designing a Real-Time Fraud Detection System

Q15: How would you design a fraud detection system for transactions?

1) Use Machine Learning for Anomaly Detection (Azure ML, AWS SageMaker).
2) Leverage Rule-Based Systems:

* Flag transactions over a certain threshold.
* Monitor unusual login locations or devices.

3) Use Stream Processing with Kafka Streams.


# 16. Avoiding Memory Leaks in Long-Running Services

Q16: Your C# service runs for days and starts consuming too much memory. How do you fix this?

1) Use Dispose and using statements for unmanaged resources.
2) Enable garbage collection (GC) logging to detect leaks.
3) Use memory profiling tools (dotMemory, PerfView).


# 17. Designing a Scalable Logging System

Q17: How do you design a logging system that scales for millions
of transactions per second?

1) Use centralized logging (Elasticsearch, Kibana, Logstash - ELK).
2) Batch logs before writing to storage to reduce IOPS.
3) logs in AWS S3 or Azure Blob for long-term retention.

# 18. Handling Time Zones in a Global Financial System

Q18: A customer in New York and another in London make transactions simultaneously.
How do you store timestamps?

1) Always store timestamps in UTC in the database.
2) Convert to the user's local time at the frontend.
3) Use DateTimeOffset in C# for time zone awareness.

# 19. Scaling a .NET API to Handle Millions of Requests

Q19: Your API is slowing down due to high traffic. How do you scale it?

1) Implement load balancing (Nginx, AWS ELB, Azure Front Door).
2) Cache frequently accessed data using Redis or MemoryCache.
3) Use Kubernetes for auto-scaling microservices.

# 20. Optimizing SQL Queries for Large Data Processing

Q20: How do you optimize an SQL query that processes millions of records?

1) Use indexes to speed up WHERE queries.
2) Use partitioning to break large tables into smaller chunks.
3) Use bulk inserts instead of row-by-row inserts.

# 21. Handling Large Reports in a Financial System

Q21: A customer requests a report for the last 2 years. How do you optimize it?

1) Use pre-aggregated tables for reports.
2) Stream reports using pagination instead of generating them all at once.
